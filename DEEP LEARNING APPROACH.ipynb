{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5578da9f",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679da6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac09ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_images(folder_path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image_name in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        img = Image.open(image_path)\n",
    "        img = img.resize((64, 64))  # Resize to match the input shape of the model\n",
    "        img = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "        images.append(img)\n",
    "        labels.append(label)  # Assign label to images in this folder\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0847289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to your two folders\n",
    "folder1_path = r'C:\\Users\\User\\Downloads\\Dataset\\zebra long wing'\n",
    "folder2_path = r'C:\\Users\\User\\Downloads\\Dataset\\wood satyr'\n",
    "0ad_and_preprocess_images(folder1_path, label=0)\n",
    "images_folder2, labels_folder2 = load_and_preprocess_images(folder2_path, label=1)\n",
    "\n",
    "# Concatenate the data from both folders\n",
    "train_images = np.concatenate((images_folder1, images_folder2), axis=0)\n",
    "train_labels = np.concatenate((labels_folder1, labels_folder2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "705c4b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu')\n",
    "])\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))  # Binary classification, so 1 neuron with sigmoid activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0477e8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Binary classification loss\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31becc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 5s 416ms/step - loss: 0.6493 - accuracy: 0.5132 - val_loss: 0.8349 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.4483 - accuracy: 0.6974 - val_loss: 0.6412 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.3210 - accuracy: 0.9211 - val_loss: 0.6202 - val_accuracy: 0.9211\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.1997 - accuracy: 0.9803 - val_loss: 0.3099 - val_accuracy: 0.9737\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9737\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 286ms/step - loss: 0.0142 - accuracy: 0.9934 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 293ms/step - loss: 0.1186 - accuracy: 0.9671 - val_loss: 6.8048e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 2s 310ms/step - loss: 0.0490 - accuracy: 0.9803 - val_loss: 0.2622 - val_accuracy: 0.9737\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 1s 286ms/step - loss: 0.0290 - accuracy: 0.9868 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 272ms/step - loss: 0.0315 - accuracy: 0.9934 - val_loss: 0.0100 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x246442eda50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4963b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9947368502616882\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = model.evaluate(train_images, train_labels, verbose=0)\n",
    "\n",
    "print(f'Validation accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f55655",
   "metadata": {},
   "source": [
    "# VG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "287c1293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0216856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 557s 9us/step\n"
     ]
    }
   ],
   "source": [
    "data_dir = r\"C:\\Users\\User\\Downloads\\Dataset\"\n",
    "classes = os.listdir(data_dir)\n",
    "X = []\n",
    "y = []\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "if class_name == \"wood satyr\":\n",
    "    label = 0\n",
    "else:\n",
    "    label = 1\n",
    "for img_name in os.listdir(class_path):\n",
    "    img_path = os.path.join(class_path, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # VGG16 expects RGB format\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    X.append(img)\n",
    "    y.append(label)\n",
    "X = np.array(X)\n",
    "\n",
    "# y = to_categorical(y) # one-hot encode the labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, np.array(y), test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Load VGG16 model without the top (fully connected) layers\n",
    "vgg = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the VGG16 layers so they're not trainable\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Create a new model on top of the VGG16 convolutional base\n",
    "model = Sequential()\n",
    "model.add(vgg)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid')) # 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5036431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 51s 16s/step - loss: 0.0000e+00 - accuracy: 0.7692 - val_loss: 0.0000e+00 - val_accuracy: 0.8000\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 49s 16s/step - loss: 0.0000e+00 - accuracy: 0.6538 - val_loss: 0.0000e+00 - val_accuracy: 0.8000\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 46s 15s/step - loss: 0.0000e+00 - accuracy: 0.7436 - val_loss: 0.0000e+00 - val_accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 47s 16s/step - loss: 0.0000e+00 - accuracy: 0.6923 - val_loss: 0.0000e+00 - val_accuracy: 0.8000\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 49s 17s/step - loss: 0.0000e+00 - accuracy: 0.6538 - val_loss: 0.0000e+00 - val_accuracy: 0.8000\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 47s 16s/step - loss: 0.0000e+00 - accuracy: 0.6154 - val_loss: 0.0000e+00 - val_accuracy: 0.8000\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 39s 13s/step - loss: 0.0000e+00 - accuracy: 0.6667 - val_loss: 0.0000e+00 - val_accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 43s 15s/step - loss: 0.0000e+00 - accuracy: 0.6795 - val_loss: 0.0000e+00 - val_accuracy: 0.8000\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 43s 15s/step - loss: 0.0000e+00 - accuracy: 0.7051 - val_loss: 0.0000e+00 - val_accuracy: 0.8000\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 46s 15s/step - loss: 0.0000e+00 - accuracy: 0.6538 - val_loss: 0.0000e+00 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.0000e+00 - accuracy: 0.8000\n",
      "Test Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Preprocess the input data for VGG16\n",
    "X_train = preprocess_input(X_train)\n",
    "X_test = preprocess_input(X_test)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87831653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
